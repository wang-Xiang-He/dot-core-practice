{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(25000,) 218 (25000,)\n","(25000,) 68 (25000,)\n"]}],"source":["import  os\n","import  tensorflow as tf\n","import  numpy as np\n","from    tensorflow import keras\n","from    tensorflow.keras import layers, losses, optimizers, Sequential\n","\n","\n","tf.random.set_seed(22)\n","np.random.seed(22)\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n","assert tf.__version__.startswith('2.')\n","\n","batchsz = 128 # 批量大小\n","total_words = 10000 # 词汇表大小N_vocab\n","max_review_len = 80 # 句子最大长度s，大于的句子部分将截断，小于的将填充\n","embedding_len = 100 # 词向量特征长度f\n","# 加载IMDB数据集，此处的数据采用数字编码，一个数字代表一个单词\n","(x_train, y_train), (x_test, y_test) = keras.datasets.imdb.load_data(num_words=total_words)\n","print(x_train.shape, len(x_train[0]), y_train.shape)\n","print(x_test.shape, len(x_test[0]), y_test.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["x_train[0]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 数字编码表\n","word_index = keras.datasets.imdb.get_word_index()\n","# for k,v in word_index.items():\n","#     print(k,v)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["word_index = {k:(v+3) for k,v in word_index.items()}\n","word_index[\"<PAD>\"] = 0\n","word_index[\"<START>\"] = 1\n","word_index[\"<UNK>\"] = 2  # unknown\n","word_index[\"<UNUSED>\"] = 3\n","# 翻转编码表\n","reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n","\n","def decode_review(text):\n","    return ' '.join([reverse_word_index.get(i, '?') for i in text])\n","\n","decode_review(x_train[8])\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print('Indexing word vectors.')\n","embeddings_index = {}\n","GLOVE_DIR = r'C:\\Users\\z390\\Downloads\\glove6b50dtxt'\n","with open(os.path.join(GLOVE_DIR, 'glove.6B.100d.txt'),encoding='utf-8') as f:\n","    for line in f:\n","        values = line.split()\n","        word = values[0]\n","        coefs = np.asarray(values[1:], dtype='float32')\n","        embeddings_index[word] = coefs\n","\n","print('Found %s word vectors.' % len(embeddings_index))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["len(embeddings_index.keys())\n","len(word_index.keys())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["MAX_NUM_WORDS = total_words\n","# prepare embedding matrix\n","num_words = min(MAX_NUM_WORDS, len(word_index))\n","embedding_matrix = np.zeros((num_words, embedding_len))\n","applied_vec_count = 0\n","for word, i in word_index.items():\n","    if i >= MAX_NUM_WORDS:\n","        continue\n","    embedding_vector = embeddings_index.get(word)\n","    # print(word,embedding_vector)\n","    if embedding_vector is not None:\n","        # words not found in embedding index will be all-zeros.\n","        embedding_matrix[i] = embedding_vector\n","        applied_vec_count += 1\n","print(applied_vec_count, embedding_matrix.shape)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# x_train:[b, 80]\n","# x_test: [b, 80]\n","# 截断和填充句子，使得等长，此处长句子保留句子后面的部分，短句子在前面填充\n","x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=max_review_len)\n","x_test = keras.preprocessing.sequence.pad_sequences(x_test, maxlen=max_review_len)\n","# 构建数据集，打散，批量，并丢掉最后一个不够batchsz的batch\n","db_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n","db_train = db_train.shuffle(1000).batch(batchsz, drop_remainder=True)\n","db_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n","db_test = db_test.batch(batchsz, drop_remainder=True)\n","print('x_train shape:', x_train.shape, tf.reduce_max(y_train), tf.reduce_min(y_train))\n","print('x_test shape:', x_test.shape)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","class MyRNN(keras.Model):\n","    # Cell方式构建多层网络\n","    def __init__(self, units):\n","        super(MyRNN, self).__init__() \n","        # 词向量编码 [b, 80] => [b, 80, 100]\n","        self.embedding = layers.Embedding(total_words, embedding_len,\n","                                          input_length=max_review_len,\n","                                          trainable=False)\n","        self.embedding.build(input_shape=(None,max_review_len))\n","        # self.embedding.set_weights([embedding_matrix])\n","        # 构建RNN\n","        self.rnn = keras.Sequential([\n","            layers.LSTM(units, dropout=0.5, return_sequences=True),\n","            layers.LSTM(units, dropout=0.5)\n","        ])\n","        # 构建分类网络，用于将CELL的输出特征进行分类，2分类\n","        # [b, 80, 100] => [b, 64] => [b, 1]\n","        self.outlayer = Sequential([\n","            layers.Dense(32),\n","            layers.Dropout(rate=0.5),\n","            layers.ReLU(),\n","            layers.Dense(1)])\n","\n","    def call(self, inputs, training=None):\n","        x = inputs # [b, 80]\n","        # embedding: [b, 80] => [b, 80, 100]\n","        x = self.embedding(x)\n","        # rnn cell compute,[b, 80, 100] => [b, 64]\n","        x = self.rnn(x)\n","        # 末层最后一个输出作为分类网络的输入: [b, 64] => [b, 1]\n","        x = self.outlayer(x,training)\n","        # p(y is pos|x)\n","        prob = tf.sigmoid(x)\n","\n","        return prob\n","\n","def main():\n","    units = 512 # RNN状态向量长度f\n","    epochs = 50 # 训练epochs\n","\n","    model = MyRNN(units)\n","    # 装配\n","    model.compile(optimizer = optimizers.Adam(0.001),\n","                  loss = losses.BinaryCrossentropy(),\n","                  metrics=['accuracy'])\n","    # 训练和验证\n","    model.fit(db_train, epochs=epochs, validation_data=db_test)\n","    # 测试\n","    model.evaluate(db_test)\n","\n","\n","if __name__ == '__main__':\n","    main()\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"interpreter":{"hash":"afce4f964eafd1ac4873ba3f5b99167ff443b723606c6cc133796e1d081bfe85"},"kernelspec":{"display_name":"Python 3.10.4 ('Demo': venv)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
